# å¯¼å…¥å¿…è¦çš„åº“
import json
import pandas as pd
import re
from typing import Dict, List, Tuple, Optional
from datetime import datetime
import zipfile
import io
# openpyxl is only required when exporting to Excel. Delay import to the export
# function to avoid ModuleNotFoundError on app startup when the package is
# missing in the runtime. If missing, we show a friendly message to the user.
_OPENPYXL_AVAILABLE = True
try:
    import openpyxl  # quick availability check
except ModuleNotFoundError:
    _OPENPYXL_AVAILABLE = False

# åœ¨æ¨¡å—çº§åˆ«å¯¼å…¥Streamlitï¼Œä½†ä¸åœ¨æ¨¡å—çº§åˆ«ä½¿ç”¨ä»»ä½•Streamlitå‡½æ•°
# è¿™æ˜¯Streamlitçš„æ¨èåšæ³•ï¼Œå¯ä»¥é¿å…æŸäº›å¯¼å…¥ç›¸å…³çš„é—®é¢˜
import streamlit as st
import time

# æ”¹è¿›çš„é˜²æŠ–å‡½æ•° - ç®€åŒ–å®ç°å¹¶ç¡®ä¿å®æ—¶å“åº”
# ä½¿ç”¨æ›´ç›´æ¥çš„æ–¹æ³•ï¼Œç¡®ä¿æ¯æ¬¡è¾“å…¥å˜åŒ–éƒ½èƒ½æ­£ç¡®è§¦å‘æœç´¢æ›´æ–°
# key_prefix: ç”¨äºæ ‡è¯†ä¸åŒæœç´¢æ¡†çš„å‰ç¼€
def debounced_search(key_prefix):
    # ç”Ÿæˆå”¯ä¸€çš„session_stateé”®å
    search_key = f"{key_prefix}_search_term"
    
    # åˆå§‹åŒ–session_stateä¸­çš„å˜é‡
    if search_key not in st.session_state:
        st.session_state[search_key] = ""
    
    return st.session_state[search_key]

# ç®€åŒ–çš„æœç´¢çŠ¶æ€æ›´æ–°å‡½æ•°
def update_search_timer(key_prefix, input_value):
    # ç›´æ¥æ›´æ–°æœç´¢è¯ï¼Œå»æ‰é˜²æŠ–å»¶è¿Ÿï¼Œç¡®ä¿å®æ—¶å“åº”
    search_key = f"{key_prefix}_search_term"
    st.session_state[search_key] = input_value  # ç›´æ¥è®¾ç½®æœç´¢è¯ï¼Œå®ç°å³æ—¶æœç´¢

class BIMParser:
    """BIMæ–‡ä»¶è§£æå™¨"""
    
    def __init__(self):
        self.raw_data = None
        self.tables_info = []
        self.columns_info = []
        self.measures_info = []
        self.relationships_info = []
        self.overview_info = []
    
    def parse_file(self, file_content: str) -> Dict:
        """è§£æBIMæ–‡ä»¶æˆ–TMSLè„šæœ¬å†…å®¹"""
        try:
            # é‡ç½®è§£æç»“æœ
            self.raw_data = None
            self.tables_info = []
            self.columns_info = []
            self.measures_info = []
            self.relationships_info = []
            self.overview_info = []

            # å°è¯•å°†ä¼ å…¥å†…å®¹è§£æä¸º JSONï¼ˆå¤§éƒ¨åˆ† .bim / TMSL ä¸º JSON æ ¼å¼ï¼‰
            try:
                parsed = json.loads(file_content)
            except Exception as e_json:
                # è¿”å›æ›´å‹å¥½çš„é”™è¯¯ä¿¡æ¯ï¼Œä¾¿äºè°ƒè¯•ä¸Šä¼ /ç²˜è´´çš„é—®é¢˜
                return {"success": False, "error": f"æ— æ³•è§£æä¸ºJSON: {str(e_json)}"}

            # è¯•å›¾å®šä½æ¨¡å‹å¯¹è±¡ï¼šå¤šæ•° .bim / TMSL JSON åŒ…å«ä¸€ä¸ªåä¸º "model" çš„å­å¯¹è±¡
            def _locate_model(obj):
                # ç›´æ¥åŒ…å« model é”®
                if isinstance(obj, dict):
                    if 'model' in obj and isinstance(obj['model'], dict):
                        return obj['model']
                    # å¸¸è§å‘½åï¼šSemanticModel
                    if 'SemanticModel' in obj and isinstance(obj['SemanticModel'], dict):
                        return obj['SemanticModel']
                    # å¦‚æœå½“å‰å¯¹è±¡çœ‹èµ·æ¥å°±æ˜¯æ¨¡å‹ï¼ˆåŒ…å« tables é”®ï¼‰
                    if 'tables' in obj and isinstance(obj['tables'], list):
                        return obj
                    # é€’å½’æŸ¥æ‰¾å­å¯¹è±¡
                    for v in obj.values():
                        if isinstance(v, (dict, list)):
                            found = _locate_model(v)
                            if found is not None:
                                return found
                elif isinstance(obj, list):
                    for item in obj:
                        if isinstance(item, (dict, list)):
                            found = _locate_model(item)
                            if found is not None:
                                return found
                return None

            model_obj = _locate_model(parsed)
            if model_obj is None:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ¨¡å‹å¯¹è±¡ï¼Œä¿ç•™åŸå§‹è§£æç»“æœä»¥ä¾¿é”™è¯¯è¿½è¸ª
                self.raw_data = parsed
            else:
                # ç»Ÿä¸€æŠŠ raw_data è®¾ç½®ä¸ºåŒ…å« model é”®çš„ç»“æ„ï¼Œæ–¹ä¾¿åç»­è§£æå‡½æ•°ä½¿ç”¨
                self.raw_data = {'model': model_obj}

            # å¡«å……è§£æä¿¡æ¯
            self._parse_tables()
            self._parse_columns()
            self._parse_measures()
            self._parse_relationships()
            self._generate_overview()
            self._resolve_all_measure_references()

            # æ‰“å°è°ƒè¯•ä¿¡æ¯ï¼ˆåœ¨æ§åˆ¶å°å¯è§ï¼‰
            print(f"è§£æç»“æœ - è¡¨æ•°é‡: {len(self.tables_info)}")
            print(f"è§£æç»“æœ - åˆ—æ•°é‡: {len(self.columns_info)}")
            print(f"è§£æç»“æœ - åº¦é‡å€¼æ•°é‡: {len(self.measures_info)}")
            print(f"è§£æç»“æœ - å…³ç³»æ•°é‡: {len(self.relationships_info)}")

            return {
                "success": True,
                "tables": self.tables_info,
                "columns": self.columns_info,
                "measures": self.measures_info,
                "relationships": self.relationships_info,
                "overview": self.overview_info
            }
        except Exception as e:
            print(f"è§£æé”™è¯¯: {str(e)}")
            return {"success": False, "error": str(e)}
    
    def _parse_tables(self):
        """è§£æè¡¨ä¿¡æ¯"""
        if "model" not in self.raw_data or "tables" not in self.raw_data["model"]:
            print("è­¦å‘Š: æ¨¡å‹æ•°æ®ä¸­æœªæ‰¾åˆ°è¡¨ä¿¡æ¯")
            return
        
        # è®°å½•åˆå§‹è¡¨æ•°é‡
        print(f"å¼€å§‹è§£æè¡¨ä¿¡æ¯ï¼ŒåŸå§‹è¡¨æ•°é‡: {len(self.raw_data['model']['tables'])}")
            
        tables = self.raw_data["model"]["tables"]
        
        # ç³»ç»Ÿè¡¨åˆ—è¡¨ï¼Œéœ€è¦æ’é™¤
        system_tables = ["User_ç”¨æˆ·æƒé™è¡¨"]
        
        for table in tables:
            table_name = table.get("name", "")
            
            # æ’é™¤ç³»ç»Ÿè¡¨
            if table_name in system_tables:
                print(f"æ’é™¤ç³»ç»Ÿè¡¨: {table_name}")
                continue
                
            source_table = "DAXåˆ›å»º"  # é»˜è®¤å€¼
            
            # æŸ¥æ‰¾æºè¡¨åé€»è¾‘
            if "partitions" in table and table["partitions"]:
                for partition in table["partitions"]:
                    if "source" in partition and "expression" in partition["source"]:
                        expression = partition["source"]["expression"]
                        source_table = self._extract_source_table(expression)
                        break
            
            # è®¡ç®—åˆ†åŒºæ•°é‡
            partition_count = 0
            if "partitions" in table:
                partition_count = len(table["partitions"])
            
            self.tables_info.append({
                "è¡¨å": table_name,
                "æºè¡¨å": source_table,
                "è¡¨åˆ†åŒºæ•°é‡": partition_count
            })
    
    def _extract_source_table(self, expression: List[str]) -> str:
        """ä»Må‡½æ•°è¡¨è¾¾å¼ä¸­æå–æºè¡¨å"""
        if not isinstance(expression, list):
            return "DAXåˆ›å»º"
        
        expression_text = "\n".join(expression)
        
        # åŒ¹é… M å‡½æ•°çš„ Item æ–¹å¼
        item_pattern = r'Item="([^"]+)"'
        item_match = re.search(item_pattern, expression_text)
        if item_match:
            return item_match.group(1)
        
        # åŒ¹é… SQL çš„ FROM è¯­å¥
        from_pattern = r'FROM\s+([a-zA-Z_][a-zA-Z0-9_]*)'
        from_match = re.search(from_pattern, expression_text, re.IGNORECASE)
        if from_match:
            return from_match.group(1)
        
        return "DAXåˆ›å»º"
    
    def _extract_connection_info(self, expression: List[str]) -> Tuple[str, str]:
        """ä»Må‡½æ•°è¡¨è¾¾å¼ä¸­æå–å®ä¾‹åœ°å€å’Œæ•°æ®åº“å"""
        if not isinstance(expression, list):
            return "", ""
        
        expression_text = "\n".join(expression)
        
        # æ¨¡å¼1: åŒ¹é… Value.NativeQuery ä¸­çš„è¿æ¥å­—ç¬¦ä¸²æ ¼å¼
        # ä¾‹å¦‚: Value.NativeQuery(#"MySql/rm-2zeu9er24zw4831e6 mysql rds aliyuncs com:3306;data_mart",...)  
        native_query_pattern = r'Value\.NativeQuery\(#"([^;]+);([^"]+)"'
        native_query_match = re.search(native_query_pattern, expression_text)
        if native_query_match:
            instance_address = native_query_match.group(1)
            db_name = native_query_match.group(2)
            return instance_address, db_name
        
        # æ¨¡å¼2: åŒ¹é… Source = #"" æ ¼å¼
        # ä¾‹å¦‚: Source = #"MySql/rm-2zeu9er24zw4831e6 mysql rds aliyuncs com:3306;data_mart"
        source_pattern = r'Source\s*=\s*#"([^;]+);([^"]+)"'
        source_match = re.search(source_pattern, expression_text)
        if source_match:
            instance_address = source_match.group(1)
            db_name = source_match.group(2)
            return instance_address, db_name
        
        # æ¨¡å¼3: ä» Schema å­—æ®µä¸­æå–æ•°æ®åº“å
        schema_pattern = r'Schema="([^"]+)"'
        schema_match = re.search(schema_pattern, expression_text)
        if schema_match:
            # å¦‚æœæ‰¾åˆ°Schemaä½†æ²¡æœ‰æ‰¾åˆ°å®Œæ•´çš„è¿æ¥ä¿¡æ¯
            # å°è¯•åªæå–æ•°æ®åº“å
            db_name = schema_match.group(1)
            return "", db_name
        
        return "", ""
    
    def _parse_columns(self):
        """è§£æåˆ—ä¿¡æ¯"""
        if "model" not in self.raw_data or "tables" not in self.raw_data["model"]:
            return
            
        tables = self.raw_data["model"]["tables"]
        
        for table in tables:
            table_name = table.get("name", "")
            source_table = "DAXåˆ›å»º"
            
            # è·å–æºè¡¨åï¼ˆå¤ç”¨è§£æé€»è¾‘ï¼‰
            if "partitions" in table and table["partitions"]:
                for partition in table["partitions"]:
                    if "source" in partition and "expression" in partition["source"]:
                        expression = partition["source"]["expression"]
                        source_table = self._extract_source_table(expression)
                        break
            
            if "columns" in table:
                for column in table["columns"]:
                    column_name = column.get("name", "")
                    data_type = column.get("dataType", "")
                    
                    # ä¼˜å…ˆä»Må‡½æ•°çš„Table.RenameColumnsä¸­æŸ¥æ‰¾æºåˆ—åï¼ˆæ–°ç‰ˆæœ¬é€»è¾‘ï¼‰
                    source_column = self._extract_column_source_from_m_function(table_name, column_name)
                    
                    # å¦‚æœMå‡½æ•°ä¸­æ‰¾ä¸åˆ°ï¼Œä½¿ç”¨sourceColumnå­—æ®µ
                    if source_column == column_name:
                        source_column = column.get("sourceColumn", "")
                    
                    # å¦‚æœsourceColumnä¹Ÿæ²¡æœ‰ï¼Œä¿ç•™åˆ—åæœ¬èº«
                    if not source_column:
                        source_column = column_name
                    
                    # å­—æ®µæ ¼å¼
                    format_string = column.get("formatString", "")
                    
                    self.columns_info.append({
                        "è¡¨å": table_name,
                        "æºè¡¨å": source_table,
                        "åˆ—å": column_name,
                        "æºåˆ—å": source_column,
                        "å­—æ®µæ ¼å¼": data_type
                    })
    
    def _extract_column_source_from_m_function(self, table_name: str, column_name: str) -> str:
        """ä»Må‡½æ•°ä¸­æå–åˆ—çš„æºåˆ—å"""
        if "model" not in self.raw_data or "tables" not in self.raw_data["model"]:
            return column_name
        
        tables = self.raw_data["model"]["tables"]
        
        # æŸ¥æ‰¾å¯¹åº”çš„è¡¨
        target_table = None
        for table in tables:
            if table.get("name", "") == table_name:
                target_table = table
                break
        
        if not target_table or "partitions" not in target_table:
            return column_name
        
        # åœ¨æ‰€æœ‰åˆ†åŒºä¸­æŸ¥æ‰¾Table.RenameColumnsæ˜ å°„
        for partition in target_table["partitions"]:
            if "source" in partition and "expression" in partition["source"]:
                expression = partition["source"]["expression"]
                
                # æŸ¥æ‰¾Table.RenameColumnsæ˜ å°„
                rename_mappings = self._extract_rename_mappings_from_m(expression)
                
                # å¦‚æœæ‰¾åˆ°åˆ—åçš„æ˜ å°„ï¼Œè¿”å›æºåˆ—å
                for original_name, source_name in rename_mappings.items():
                    if original_name == column_name:
                        return source_name
        
        return column_name
    
    def _extract_rename_mappings_from_m(self, expression: str) -> dict:
        """ä»Mè¡¨è¾¾å¼ä¸­æå–Table.RenameColumnsæ˜ å°„"""
        rename_mappings = {}
        
        # å¤„ç†expressionå¯èƒ½æ˜¯åˆ—è¡¨çš„æƒ…å†µ
        if isinstance(expression, list):
            expression = " ".join(expression)
        
        # æŸ¥æ‰¾Table.RenameColumnsæ¨¡å¼
        # æ¨¡å¼ï¼šTable.RenameColumns(#table(...), {"old1", "new1"}, {"old2", "new2"}, ...)
        import re
        
        # æŸ¥æ‰¾Table.RenameColumnså‡½æ•°è°ƒç”¨
        rename_pattern = r'Table\.RenameColumns\([^,]+,\s*(\{[^}]*(?:\{[^}]*}[^}]*)*})\)'
        matches = re.findall(rename_pattern, expression)
        
        for match in matches:
            # æå–æ˜ å°„å¯¹
            mapping_pairs = re.findall(r'\{\s*"([^"]+)"\s*,\s*"([^"]+)"\s*}', match)
            
            for old_name, new_name in mapping_pairs:
                rename_mappings[new_name] = old_name  # æ˜ å°„æ˜¯ new -> old
        
        # ä¹Ÿå°è¯•åŒ¹é…ä¸å¸¦å¼•å·çš„æ˜ å°„
        if not rename_mappings:
            for match in matches:
                mapping_pairs = re.findall(r'\{\s*([a-zA-Z_][a-zA-Z0-9_]*)\s*,\s*"([^"]+)"\s*}', match)
                for old_name, new_name in mapping_pairs:
                    rename_mappings[new_name] = old_name
        
        return rename_mappings
    
    def _parse_measures(self):
        """è§£æåº¦é‡å€¼ä¿¡æ¯"""
        if "model" not in self.raw_data or "tables" not in self.raw_data["model"]:
            return
            
        # é¦–å…ˆæ„å»ºè¡¨ååˆ°æºè¡¨åçš„lookupè¡¨å’Œåˆ—ååˆ°æºåˆ—åçš„lookupè¡¨
        table_source_lookup = {}
        column_source_lookup = {}
        tables = self.raw_data["model"]["tables"]
        
        # æ„å»ºè¡¨ååˆ°æºè¡¨åçš„æ˜ å°„
        for table in tables:
            table_name = table.get("name", "")
            source_table = "DAXåˆ›å»º"
            
            # æŸ¥æ‰¾æºè¡¨åé€»è¾‘
            if "partitions" in table and table["partitions"]:
                for partition in table["partitions"]:
                    if "source" in partition and "expression" in partition["source"]:
                        expression = partition["source"]["expression"]
                        source_table = self._extract_source_table(expression)
                        break
            
            table_source_lookup[table_name] = source_table
            
            # æ„å»ºåˆ—ååˆ°æºåˆ—åçš„æ˜ å°„
            if "columns" in table:
                for column in table["columns"]:
                    column_name = column.get("name", "")
                    source_column = column.get("sourceColumn", column_name)
                    
                    # å°è¯•ä»Må‡½æ•°ä¸­è·å–æ›´å‡†ç¡®çš„æºåˆ—å
                    m_source_column = self._extract_column_source_from_m_function(table_name, column_name)
                    if m_source_column != column_name:
                        source_column = m_source_column
                    
                    column_source_lookup[f"{table_name}.{column_name}"] = source_column
        
        # å…ˆæ”¶é›†æ‰€æœ‰åº¦é‡å€¼ä¿¡æ¯ï¼Œç”¨äºåç»­è§£æå¼•ç”¨
        all_measures = []
        for table in tables:
            if "measures" in table:
                for measure in table["measures"]:
                    measure_name = measure.get("name", "")
                    expression = measure.get("expression", "")
                    
                    # å¤„ç†æ•°ç»„æ ¼å¼çš„expression
                    if isinstance(expression, list):
                        expression = " ".join(expression)
                    
                    format_string = measure.get("formatString", "")
                    display_folder = measure.get("displayFolder", "")
                    table_name = table.get("name", "")
                    
                    # æ›¿æ¢è½¬ä¹‰å­—ç¬¦
                    expression = expression.replace('\\"', '"')
                    
                    all_measures.append({
                        "åº¦é‡å€¼åç§°": measure_name,
                        "åº¦é‡å€¼è®¡ç®—é€»è¾‘": expression,
                        "åº¦é‡å€¼æ•°æ®ç±»å‹": format_string,
                        "åº¦é‡å€¼æ–‡ä»¶å¤¹": display_folder,
                        "æ‰€å±è¡¨": table_name
                    })
        
        # åˆ›å»ºåº¦é‡å€¼æŸ¥æ‰¾å­—å…¸
        measure_lookup = {measure["åº¦é‡å€¼åç§°"]: measure for measure in all_measures}
        
        # ä¸ºæ¯ä¸ªåº¦é‡å€¼è§£ææ¶‰åŠçš„è¡¨ã€åˆ—å’Œå¼•ç”¨çš„åº¦é‡å€¼
        for measure in all_measures:
            measure_name = measure["åº¦é‡å€¼åç§°"]
            expression = measure["åº¦é‡å€¼è®¡ç®—é€»è¾‘"]
            
            # æå–å½“å‰è¡¨è¾¾å¼ä¸­çš„è¡¨å’Œåˆ—
            current_tables = self._extract_involved_tables(expression)
            current_columns = self._extract_involved_columns(expression)
            
            # é€’å½’æŸ¥æ‰¾å¼•ç”¨çš„åº¦é‡å€¼çš„DAXé€»è¾‘ï¼Œå¹¶åˆå¹¶è¡¨å’Œåˆ—ä¿¡æ¯
            all_tables = set(current_tables)
            all_columns = set(current_columns)
            visited_measures = set()  # é¿å…å¾ªç¯å¼•ç”¨
            
            def resolve_measure_references(measure_expr):
                # æŸ¥æ‰¾å¼•ç”¨çš„åº¦é‡å€¼
                measure_pattern = r"\[([^\]]+)\]"
                matches = re.findall(measure_pattern, measure_expr)
                
                for match in matches:
                    # æ£€æŸ¥æ˜¯å¦æ˜¯å·²å®šä¹‰çš„åº¦é‡å€¼
                    if match in measure_lookup and match not in visited_measures:
                        visited_measures.add(match)
                        referenced_measure = measure_lookup[match]
                        # åˆå¹¶è¢«å¼•ç”¨åº¦é‡å€¼æ¶‰åŠçš„è¡¨å’Œåˆ—
                        ref_tables = self._extract_involved_tables(referenced_measure["åº¦é‡å€¼è®¡ç®—é€»è¾‘"])
                        ref_columns = self._extract_involved_columns(referenced_measure["åº¦é‡å€¼è®¡ç®—é€»è¾‘"])
                        all_tables.update(ref_tables)
                        all_columns.update(ref_columns)
                        # é€’å½’å¤„ç†åµŒå¥—å¼•ç”¨
                        resolve_measure_references(referenced_measure["åº¦é‡å€¼è®¡ç®—é€»è¾‘"])
            
            # å¼€å§‹é€’å½’è§£æå¼•ç”¨
            resolve_measure_references(expression)
            
            # æ ¼å¼åŒ–æ¶‰åŠè¡¨ï¼ˆä½¿ç”¨ä¸è¡¨å…³ç³»é¡µç›¸åŒçš„æ˜¾ç¤ºæ–¹å¼ï¼‰
            formatted_tables = []
            for table_involved in all_tables:
                source_table = table_source_lookup.get(table_involved, "DAXåˆ›å»º")
                formatted_tables.append(f"{table_involved} (æºè¡¨: {source_table})")
            
            # æ ¼å¼åŒ–æ¶‰åŠåˆ—ï¼ˆä½¿ç”¨ä¸è¡¨å…³ç³»é¡µç›¸åŒçš„æ˜¾ç¤ºæ–¹å¼ï¼Œä»column_source_lookupè·å–æºåˆ—åï¼‰
            formatted_columns = []
            for table_involved in all_tables:
                # æŸ¥æ‰¾å½“å‰è¡¨ä¸­æ¶‰åŠçš„åˆ—
                table_related_columns = []
                for column_involved in all_columns:
                    # å°è¯•ä»DAXè¡¨è¾¾å¼ä¸­æå–åˆ—æ‰€å±çš„è¡¨
                    # é€šè¿‡æ­£åˆ™è¡¨è¾¾å¼åŒ¹é… 'è¡¨å'[åˆ—å] æ¨¡å¼
                    column_pattern = rf"'{re.escape(table_involved)}'\[([^\]]+)\]"
                    column_matches = re.findall(column_pattern, expression)
                    
                    # æ£€æŸ¥åˆ—æ˜¯å¦å±äºå½“å‰è¡¨
                    if column_involved in column_matches:
                        table_related_columns.append(column_involved)
                
                # ä¸ºæ¯ä¸ªåˆ—æ ¼å¼åŒ–æ˜¾ç¤ºï¼Œåªæ˜¾ç¤ºåˆ—åå’Œæºåˆ—
                for column_involved in table_related_columns:
                    source_column = column_source_lookup.get(f"{table_involved}.{column_involved}", column_involved)
                    formatted_columns.append(f"{column_involved} (æºåˆ—: {source_column})")
            
            # å°†è§£æç»“æœæ·»åŠ åˆ°æœ€ç»ˆåˆ—è¡¨
            self.measures_info.append({
                "åº¦é‡å€¼åç§°": measure_name,
                "åº¦é‡å€¼è®¡ç®—é€»è¾‘": expression,
                "åº¦é‡å€¼æ•°æ®ç±»å‹": measure["åº¦é‡å€¼æ•°æ®ç±»å‹"],
                "åº¦é‡å€¼æ–‡ä»¶å¤¹": measure["åº¦é‡å€¼æ–‡ä»¶å¤¹"],
                "åº¦é‡å€¼æ¶‰åŠè¡¨": "\n".join(formatted_tables),
                "åº¦é‡å€¼æ¶‰åŠåˆ—": "\n".join(formatted_columns)
            })
    
    def _extract_involved_tables(self, expression: str) -> List[str]:
        """ä»DAXè¡¨è¾¾å¼ä¸­æå–æ¶‰åŠçš„è¡¨"""
        tables = []
        # åŒ¹é… 'è¡¨å'[åˆ—å] æ¨¡å¼
        table_pattern = r"'([^']+)'"
        matches = re.findall(table_pattern, expression)
        tables.extend(matches)
        return list(set(tables))
    
    def _extract_involved_columns(self, expression: str) -> List[str]:
        """ä»DAXè¡¨è¾¾å¼ä¸­æå–æ¶‰åŠçš„åˆ—"""
        columns = []
        # åŒ¹é… 'è¡¨å'[åˆ—å] æ¨¡å¼ï¼Œæå–åˆ—å
        column_pattern = r"'[^']+'" + r"\[" + r"'([^']+)'" + r"\]|'[^']+'" + r"\[([^\]]+)\]"
        matches = re.findall(column_pattern, expression)
        for match in matches:
            if isinstance(match, tuple):
                columns.extend([m for m in match if m])
            else:
                columns.append(match)
        return list(set(columns))
    
    def _parse_relationships(self):
        """è§£æè¡¨å…³ç³»ä¿¡æ¯"""
        if "model" not in self.raw_data or "relationships" not in self.raw_data["model"]:
            return
            
        # é¦–å…ˆæ„å»ºè¡¨ååˆ°æºè¡¨åçš„lookupè¡¨
        table_source_lookup = {}
        tables = self.raw_data["model"]["tables"]
        
        for table in tables:
            table_name = table.get("name", "")
            source_table = "DAXåˆ›å»º"
            
            # æŸ¥æ‰¾æºè¡¨åé€»è¾‘ï¼ˆå¤ç”¨ä¹‹å‰çš„é€»è¾‘ï¼‰
            if "partitions" in table and table["partitions"]:
                for partition in table["partitions"]:
                    if "source" in partition and "expression" in partition["source"]:
                        expression = partition["source"]["expression"]
                        source_table = self._extract_source_table(expression)
                        break
            
            table_source_lookup[table_name] = source_table
        
        # æ„å»ºåˆ—ååˆ°æºåˆ—åçš„lookupè¡¨
        column_source_lookup = {}
        for table in tables:
            table_name = table.get("name", "")
            
            if "columns" in table:
                for column in table["columns"]:
                    column_name = column.get("name", "")
                    source_column = column.get("sourceColumn", column_name)
                    
                    # å°è¯•ä»Må‡½æ•°ä¸­è·å–æ›´å‡†ç¡®çš„æºåˆ—å
                    m_source_column = self._extract_column_source_from_m_function(table_name, column_name)
                    if m_source_column != column_name:
                        source_column = m_source_column
                    
                    column_source_lookup[f"{table_name}.{column_name}"] = source_column
        
        # è§£æå…³ç³»
        relationships = self.raw_data["model"]["relationships"]
        
        for relationship in relationships:
            from_table = relationship.get("fromTable", "")
            from_column = relationship.get("fromColumn", "")
            to_table = relationship.get("toTable", "")
            to_column = relationship.get("toColumn", "")
            # è§£æå…³ç³»ç±»å‹
            to_cardinality = relationship.get("toCardinality", "")
            cardinality = "å¤šå¯¹å¤š" if to_cardinality else "ä¸€å¯¹å¤š"
            
            # è§£æç­›é€‰æ–¹å‘
            cross_filtering_behavior = relationship.get("crossFilteringBehavior", "")
            cross_filtering_behavior = "åŒå‘" if cross_filtering_behavior else "å•å‘"
            
            # è§£ææ˜¯å¦æ´»åŠ¨
            is_active = relationship.get("isActive", True)
            security_filtering_behavior = "æœªå¯ç”¨" if is_active is False else "å¯ç”¨"
            
            # è·å–æºè¡¨å
            from_source_table = table_source_lookup.get(from_table, "DAXåˆ›å»º")
            to_source_table = table_source_lookup.get(to_table, "DAXåˆ›å»º")
            
            # è·å–æºåˆ—å
            from_source_column = column_source_lookup.get(f"{from_table}.{from_column}", from_column)
            to_source_column = column_source_lookup.get(f"{to_table}.{to_column}", to_column)
            
            self.relationships_info.append({
                "æºè¡¨å": f"{from_table}\n(æºè¡¨: {from_source_table})",
                "æºè¡¨å­—æ®µ": f"{from_column}\n(æºåˆ—: {from_source_column})",
                "ç›®æ ‡è¡¨å": f"{to_table}\n(æºè¡¨: {to_source_table})",
                "ç›®æ ‡è¡¨å­—æ®µ": f"{to_column}\n(æºåˆ—: {to_source_column})",
                "å…³ç³»ç±»å‹": cardinality,
                "ç­›é€‰æ–¹å‘": cross_filtering_behavior,
                "æ˜¯å¦æ´»åŠ¨": security_filtering_behavior
            })
    
    def _resolve_all_measure_references(self):
        """å¤„ç†æ‰€æœ‰åº¦é‡å€¼ä¹‹é—´çš„å¼•ç”¨å…³ç³»"""
        # é¦–å…ˆåˆ›å»ºä¸€ä¸ªåº¦é‡å€¼åç§°åˆ°å…¶ä¿¡æ¯çš„æ˜ å°„
        measure_lookup = {}
        for measure in self.measures_info:
            measure_lookup[measure["åº¦é‡å€¼åç§°"]] = measure
        
        # æ›´æ–°æ¯ä¸ªåº¦é‡å€¼ï¼Œæ·»åŠ å¯¹å…¶ä»–åº¦é‡å€¼çš„å¼•ç”¨ä¿¡æ¯
        for measure in self.measures_info:
            expression = measure["åº¦é‡å€¼è®¡ç®—é€»è¾‘"]
            referenced_measures = []
            
            # æŸ¥æ‰¾å¼•ç”¨çš„åº¦é‡å€¼ï¼ˆå‡è®¾åº¦é‡å€¼åœ¨è¡¨è¾¾å¼ä¸­ä»¥ [åº¦é‡å€¼åç§°] æ ¼å¼å‡ºç°ï¼‰
            measure_pattern = r"\[([^\]]+)\]"
            matches = re.findall(measure_pattern, expression)
            
            for match in matches:
                # æ’é™¤å¯èƒ½çš„åˆ—å¼•ç”¨ï¼ˆé€šè¿‡ä¸Šä¸‹æ–‡åˆ¤æ–­ï¼‰
                # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå‡è®¾æ²¡æœ‰è¡¨é™å®šçš„å°±æ˜¯åº¦é‡å€¼
                if match in measure_lookup and match not in referenced_measures:
                    referenced_measures.append(match)
            
            # å°†å¼•ç”¨çš„åº¦é‡å€¼ä¿¡æ¯æ·»åŠ åˆ°å½“å‰åº¦é‡å€¼ä¸­
            if referenced_measures:
                measure["åº¦é‡å€¼å¼•ç”¨"] = "\n".join(referenced_measures)
            else:
                measure["åº¦é‡å€¼å¼•ç”¨"] = ""
    
    def _generate_overview(self):
        """ç”Ÿæˆæ¨¡å‹æ¦‚è§ˆä¿¡æ¯"""
        if "model" not in self.raw_data:
            return
        
        # è·å–æ‰€æœ‰è¡¨çš„ä¿¡æ¯
        tables = self.raw_data["model"].get("tables", [])
        
        # é¦–å…ˆè§£ææ‰€æœ‰åº¦é‡å€¼ï¼Œæ”¶é›†æ¯ä¸ªè¡¨æ¶‰åŠçš„åº¦é‡å€¼
        table_measure_counts = {}
        for table in tables:
            table_name = table.get("name", "")
            # åˆå§‹åŒ–æ¯ä¸ªè¡¨çš„åº¦é‡å€¼è®¡æ•°ä¸º0
            table_measure_counts[table_name] = 0
        
        # è®¡ç®—æ¯ä¸ªè¡¨ç›¸å…³çš„åº¦é‡å€¼æ•°é‡
        for table in tables:
            if "measures" in table:
                for measure in table["measures"]:
                    expression = measure.get("expression", "")
                    # å¤„ç†æ•°ç»„æ ¼å¼çš„expression
                    if isinstance(expression, list):
                        expression = " ".join(expression)
                    # æå–æ¶‰åŠçš„è¡¨
                    involved_tables = self._extract_involved_tables(expression)
                    # å¦‚æœåº¦é‡å€¼æ¶‰åŠæ­¤è¡¨ï¼Œåˆ™å°†è¯¥è¡¨çš„åº¦é‡å€¼è®¡æ•°åŠ 1
                    for involved_table in involved_tables:
                        if involved_table in table_measure_counts:
                            table_measure_counts[involved_table] += 1
        
        # ç”Ÿæˆæ¦‚è§ˆä¿¡æ¯
        for table in tables:
            table_name = table.get("name", "")
            
            # ç»Ÿè®¡åˆ—æ•°å’Œåˆ†åŒºæ•°
            column_count = len(table.get("columns", []))
            partition_count = len(table.get("partitions", []))
            
            # è·å–æºè¡¨åå’Œè¿æ¥ä¿¡æ¯
            source_table = "DAXåˆ›å»º"
            instance_address = ""
            database_name = ""
            protocol = ""
            
            if "partitions" in table and table["partitions"]:
                for partition in table["partitions"]:
                    if "source" in partition and "expression" in partition["source"]:
                        expression = partition["source"]["expression"]
                        source_table = self._extract_source_table(expression)
                        # æå–å®ä¾‹åœ°å€å’Œæ•°æ®åº“å
                        instance_address, database_name = self._extract_connection_info(expression)
                        # æå–åè®®ç±»å‹
                        if instance_address and '/' in instance_address:
                            protocol = instance_address.split('/')[0]
                        break
            
            # è·å–è¯¥è¡¨æ¶‰åŠçš„åº¦é‡å€¼æ•°é‡
            measure_count = table_measure_counts.get(table_name, 0)
            
            self.overview_info.append({
                "è¡¨å": table_name,
                "æºè¡¨å": source_table,
                "åˆ—æ•°": column_count,
                "åº¦é‡å€¼æ•°": measure_count,
                "åˆ†åŒºæ•°": partition_count,
                "å®ä¾‹åœ°å€": instance_address,
                "æ•°æ®åº“å": database_name,
                "åè®®": protocol
            })

def create_streamlit_app():
    """åˆ›å»ºStreamlitåº”ç”¨"""
    # è®¾ç½®é¡µé¢é…ç½®
    st.set_page_config(
        page_title="BIæ¨¡å‹è§£æå·¥å…·",
        page_icon="ğŸ“Š",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # æ·»åŠ å…¨å±€CSSæ ·å¼
    st.markdown("""
    <style>
    /* ä¾§è¾¹æ æ ·å¼ä¼˜åŒ– */
    [data-testid="stSidebar"] {
        background-color: #f8f9fa;
    }
    
    /* æ–‡ä»¶ä¸Šä¼ åŒºåŸŸæ ·å¼ä¼˜åŒ– */
    [data-testid="stFileUploader"] {
        border: 2px dashed #0066cc;
        border-radius: 0.5rem;
        padding: 1rem;
        background-color: #f0f7ff;
    }
    
    /* æ ‡é¢˜æ ·å¼ä¼˜åŒ– */
    h1, h2, h3, h4 {
        color: #1a1a1a;
        font-weight: bold;
        font-family: 'Microsoft YaHei', Arial, sans-serif;
    }
    
    /* æŒ‰é’®æ ·å¼ä¼˜åŒ– */
    [data-baseweb="button"] {
        background-color: #0066cc !important;
        color: white !important;
        border-radius: 0.25rem !important;
        font-weight: bold !important;
    }
    
    /* è®¾ç½®Streamlitæ ¹å®¹å™¨å’Œä¸»å†…å®¹åŒºåŸŸèƒŒæ™¯ä¸ºé»‘è‰² */
    [data-testid="stApp"] {
        background-color: #000000 !important;
    }
    
    [data-testid="stAppViewContainer"] {
        background-color: #000000 !important;
    }
    
    /* è®¾ç½®ä¾§è¾¹æ èƒŒæ™¯ä¸ºé»‘è‰² */
    [data-testid="stSidebar"] {
        background-color: #000000 !important;
    }
    
    /* å…¨å±€æ ·å¼é‡ç½® - ç¡®ä¿æ‰€æœ‰é¡µé¢æ‰€æœ‰è¡¨æ ¼å…ƒç´ é å·¦å¹¶è®¾ç½®ç™½è‰²å­—ä½“ */
    body * {
        --st-text-align: left !important;
        color: #ffffff !important;
    }
    
    /* ç¡®ä¿å†…å®¹åŒºåŸŸå¯è¯»æ€§ */
    .main .block-container {
        background-color: #000000 !important;
        color: #ffffff !important;
    }
    
    /* ç¡®ä¿æ‰€æœ‰æ–‡æœ¬å…ƒç´ ä¸ºç™½è‰² */
    h1, h2, h3, h4, h5, h6, p, span, div, label, button {
        color: #ffffff !important;
    }
    
    /* ç¡®ä¿è¡¨æ ¼å…ƒç´ ä¸ºç™½è‰² */
    table, th, td {
        color: #ffffff !important;
        border-color: #333333 !important;
    }
    
    /* ç¡®ä¿è¾“å…¥æ¡†å’Œé€‰æ‹©æ¡†çš„å¯è¯»æ€§ */
    input, select, textarea {
        background-color: #333333 !important;
        color: #ffffff !important;
        border-color: #555555 !important;
    }
    
    /* è®¾ç½®æ–‡ä»¶ä¸Šä¼ æ¡†ä½“èƒŒæ™¯ä¸ºé»‘è‰² */
    .st-emotion-cache-1sv6ehc {
        background-color: #000000 !important;
        border-color: #555555 !important;
    }
    
    /* ç¡®ä¿æ‰€æœ‰æ–‡ä»¶ä¸Šä¼ ç›¸å…³å…ƒç´ ä¸ºé»‘è‰²èƒŒæ™¯ */
    .stFileUploader, .st-file-uploader {
        background-color: #000000 !important;
    }
    
    /* ç¡®ä¿æ–‡ä»¶ä¸Šä¼ æŒ‰é’®çš„æ ·å¼ */
    .st-emotion-cache-166asn9 {
        background-color: #000000 !important;
        border-color: #555555 !important;
    }
    
    /* ç¡®ä¿æ‹–æ”¾åŒºåŸŸçš„æ ·å¼ */
    .st-dg {
        background-color: #000000 !important;
        border-color: #555555 !important;
    }
    
    /* ç¡®ä¿ä¾§è¾¹æ æŠ˜å å’Œå±•å¼€æŒ‰é”®å§‹ç»ˆæ˜¾ç¤º - åŒ…æ‹¬æ‰€æœ‰çŠ¶æ€ */
    /* æŠ˜å æŒ‰é’® (å‘å³ç®­å¤´) */
    [data-testid="stIconMaterial"][data-testid="collapsedControl"] {
        color: #ffffff !important;
        opacity: 1 !important;
        display: block !important;
    }
    
    /* å±•å¼€æŒ‰é’® (å‘å·¦ç®­å¤´) */
    [data-testid="stIconMaterial"][data-testid="expandedControl"] {
        color: #ffffff !important;
        opacity: 1 !important;
        display: block !important;
    }
    
    /* ç¡®ä¿æ‰€æœ‰stIconMaterialå›¾æ ‡å§‹ç»ˆå¯è§ */
    [data-testid="stIconMaterial"] {
        color: #ffffff !important;
        opacity: 1 !important;
        display: block !important;
    }
    
    /* ç¡®ä¿ä¾§è¾¹æ æ§åˆ¶åŒºåŸŸå§‹ç»ˆå¯è§ */
    [data-testid="collapsedControl"], [data-testid="expandedControl"] {
        opacity: 1 !important;
        display: flex !important;
        visibility: visible !important;
    }
    
    /* ç¡®ä¿ä¾§è¾¹æ æ§åˆ¶æŒ‰é’®å®¹å™¨å§‹ç»ˆæ˜¾ç¤º */
    .st-emotion-cache-1v0mbdj,
    .st-emotion-cache-ujm5ma,
    .st-emotion-cache-1nqbn9b {
        opacity: 1 !important;
        display: block !important;
        visibility: visible !important;
    }
    
    /* è¦†ç›–ä»»ä½•æ‚¬åœç›¸å…³çš„æ ·å¼ */
    .st-emotion-cache-1v0mbdj:hover,
    [data-testid="collapsedControl"]:hover,
    [data-testid="expandedControl"]:hover {
        opacity: 1 !important; /* ä¿æŒä¸é€æ˜ */
    }
    
    /* ç¡®ä¿ä¾§è¾¹æ éšè—æ—¶æ§åˆ¶åŒºåŸŸä¹Ÿå¯è§ */
    .css-1d391kg {
        visibility: visible !important;
        opacity: 1 !important;
    }
    
    /* è¡¨æ ¼æ ·å¼ä¼˜åŒ– */
    [data-testid="stDataFrame"], [data-testid="stTable"] {
        font-family: 'Microsoft YaHei', Arial, sans-serif;
        font-size: 14px;
        /* ç¡®ä¿æ•´ä¸ªè¡¨æ ¼å®¹å™¨å·¦å¯¹é½ */
        display: block !important;
        text-align: left !important;
    }
    
    /* é‡ç‚¹ï¼šç¡®ä¿æ‰€æœ‰é¡µé¢æ‰€æœ‰è¡¨æ ¼çš„å•å…ƒæ ¼å†…å®¹é å·¦å¯¹é½ */
    /* ç›´æ¥é’ˆå¯¹æ‰€æœ‰è¡¨æ ¼å•å…ƒæ ¼å†…å®¹çš„æ ·å¼ï¼Œæœ€é«˜ä¼˜å…ˆçº§ */
    [data-testid="stDataFrame"] tbody td,
    [data-testid="stTable"] tbody td,
    [data-testid="columns_table"] tbody td,
    [data-testid="measures_table"] tbody td,
    [data-testid="relationships_table"] tbody td,
    table tbody td {
        text-align: left !important;
        text-align-last: left !important;
        /* ç¡®ä¿æ–‡æœ¬å†…å®¹é å·¦ */
        justify-content: flex-start !important;
        align-items: flex-start !important;
        /* ç¡®ä¿å•å…ƒæ ¼å†…éƒ¨å…ƒç´ é å·¦ */
        display: table-cell !important;
        /* é‡ç½®å¯èƒ½çš„displayå±æ€§ */
        vertical-align: top !important;
        /* ç¡®ä¿å†…å®¹ä»å·¦ä¾§å¼€å§‹ */
        padding-left: 8px !important;
        padding-right: 8px !important;
    }
    
    /* ç¡®ä¿æ‰€æœ‰é¡µé¢å•å…ƒæ ¼å†…æ‰€æœ‰å†…å®¹å…ƒç´ é å·¦ */
    [data-testid="stDataFrame"] td *,
    [data-testid="stTable"] td *,
    [data-testid="columns_table"] td *,
    [data-testid="measures_table"] td *,
    [data-testid="relationships_table"] td *,
    table td * {
        text-align: left !important;
        text-align-last: left !important;
        justify-content: flex-start !important;
        align-items: flex-start !important;
        display: inline !important;
        /* ç¡®ä¿å†…å®¹å…ƒç´ ä¿æŒå†…è”çŠ¶æ€ */
    }
    
    /* è¡¨æ ¼å†…éƒ¨æ‰€æœ‰å…ƒç´ å·¦å¯¹é½ - è¦†ç›–æ‰€æœ‰é¡µé¢ */
    [data-testid="stDataFrame"] *, 
    [data-testid="stTable"] *, 
    [data-testid="columns_table"] *, 
    [data-testid="measures_table"] *, 
    [data-testid="relationships_table"] *, 
    table * {
        text-align: left !important;
        justify-content: flex-start !important;
        align-items: flex-start !important;
    }
    
    /* è¡¨æ ¼ä¸»ä½“å†…å®¹å·¦å¯¹é½ - è¦†ç›–æ‰€æœ‰é¡µé¢ */
    [data-testid="stDataFrame"] tbody, 
    [data-testid="stTable"] tbody,
    [data-testid="columns_table"] tbody,
    [data-testid="measures_table"] tbody,
    [data-testid="relationships_table"] tbody,
    table tbody {
        text-align: left !important;
    }
    
    [data-testid="stDataFrame"] tbody tr, 
    [data-testid="stTable"] tbody tr,
    [data-testid="columns_table"] tbody tr,
    [data-testid="measures_table"] tbody tr,
    [data-testid="relationships_table"] tbody tr,
    table tbody tr {
        text-align: left !important;
    }
    
    /* é’ˆå¯¹Streamlitçš„è¡¨æ ¼åº•å±‚å®ç° - è¦†ç›–æ‰€æœ‰é¡µé¢ */
    .dataframe, 
    .dataframe tbody, 
    .dataframe tr, 
    .dataframe td, 
    .dataframe th {
        text-align: left !important;
        text-align-last: left !important;
    }
    
    /* é’ˆå¯¹pandasè¡¨æ ¼çš„é¢å¤–æ ·å¼ - è¦†ç›–æ‰€æœ‰é¡µé¢ */
    .stDataFrame, .stTable {
        text-align: left !important;
    }
    
    .stDataFrame td, .stTable td {
        text-align: left !important;
        text-align-last: left !important;
    }
    
    /* é˜²æ­¢Streamlité»˜è®¤æ ·å¼è¦†ç›– - è¦†ç›–æ‰€æœ‰é¡µé¢ */
    [data-baseweb="table"] {
        text-align: left !important;
    }
    
    [data-baseweb="table"] td {
        text-align: left !important;
        text-align-last: left !important;
        display: table-cell !important;
        vertical-align: top !important;
    }
    
    [data-baseweb="table"] tbody td {
        text-align: left !important;
        text-align-last: left !important;
        display: table-cell !important;
        vertical-align: top !important;
    }
    
    /* é’ˆå¯¹ä¸åŒé¡µé¢çš„ç‰¹å®šè¡¨æ ¼ID */
    [data-testid="columns_table"], 
    [data-testid="measures_table"], 
    [data-testid="relationships_table"] {
        text-align: left !important;
        width: 100% !important;
        display: block !important;
    }
    
    /* ç¡®ä¿æ‰€æœ‰è¡¨æ ¼ä¸­æ‰€æœ‰æ–‡æœ¬å†…å®¹é å·¦ */
    [data-testid="stDataFrame"] text,
    [data-testid="stTable"] text,
    [data-testid="columns_table"] text,
    [data-testid="measures_table"] text,
    [data-testid="relationships_table"] text {
        text-anchor: start !important;
        dominant-baseline: hanging !important;
    }
    
    /* ç¡®ä¿Streamlitçš„å†…éƒ¨è¡¨æ ¼ç»„ä»¶é å·¦ */
    ._StyledTable {
        text-align: left !important;
    }
    
    /* ç¡®ä¿æ‰€æœ‰æ•°æ®æ˜¾ç¤ºç›¸å…³ç»„ä»¶é å·¦ */
    .data-table,
    .table-wrapper,
    .streamlit-expanderHeader {
        text-align: left !important;
    }
    
    /* æ»šåŠ¨æ¡æ ·å¼ä¼˜åŒ– */
    ::-webkit-scrollbar {
        width: 8px;
        height: 8px;
    }
    
    ::-webkit-scrollbar-track {
        background: #f1f1f1;
        border-radius: 4px;
    }
    
    ::-webkit-scrollbar-thumb {
        background: #c1c1c1;
        border-radius: 4px;
    }
    
    ::-webkit-scrollbar-thumb:hover {
        background: #a1a1a1;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    if 'parsed_data' not in st.session_state:
        st.session_state['parsed_data'] = None
    
    # ä¾§è¾¹æ 
    with st.sidebar:
        # æ–‡ä»¶ä¸Šä¼ 
        uploaded_file = st.file_uploader("ğŸ“ ä¸Šä¼ BIæ¨¡å‹æ–‡ä»¶ (.bim)", type="bim")
        
        # åªä¿ç•™ä¸€ä¸ªæœ‰æ•ˆçš„è§£ææŒ‰é’®
        parse_button = st.button("ğŸš€ å¼€å§‹è§£æ", key="parse_button", help="å¼€å§‹è§£æä¸Šä¼ çš„æ¨¡å‹æ–‡ä»¶", use_container_width=True)
        
        # æ·»åŠ TMSLè„šæœ¬ä¸Šä¼ æŒ‰é’®
        paste_upload_button = st.button("ğŸ“‹ ä¸Šä¼ TMSLè„šæœ¬", key="paste_upload_button", help="é€šè¿‡ç²˜è´´æ–¹å¼ä¸Šä¼ TMSLè„šæœ¬", use_container_width=True)
    
    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    if "show_paste_dialog" not in st.session_state:
        st.session_state["show_paste_dialog"] = False
    
    # åˆ‡æ¢å¼¹çª—æ˜¾ç¤ºçŠ¶æ€
    if paste_upload_button:
        st.session_state["show_paste_dialog"] = True
    
    # ä½¿ç”¨Streamlitçš„å®¹å™¨ä½œä¸ºå¼¹çª—æ›¿ä»£ä¸å…¼å®¹çš„dialogåŠŸèƒ½
    if st.session_state["show_paste_dialog"]:
        # ä½¿ç”¨å®¹å™¨æ¨¡æ‹Ÿå¯¹è¯æ¡†æ•ˆæœ
        st.markdown("## ğŸ“‹ ä¸Šä¼ TMSLè„šæœ¬")
        st.markdown("---")
        # æ·»åŠ æç¤ºä¿¡æ¯ï¼Œè¯´æ˜è¿™æ˜¯ä¸€ä¸ªæ¨¡æ€ç¼–è¾‘åŒºåŸŸ
        st.info("ğŸ’¡ è¿™æ˜¯ä¸€ä¸ªæ¨¡æ€ç¼–è¾‘åŒºåŸŸï¼Œå®Œæˆç¼–è¾‘åç‚¹å‡»è§£ææˆ–å…³é—­æŒ‰é’®ã€‚")
        # ä½¿ç”¨å®¹å™¨åŒ…è£¹å†…å®¹
        # ä½¿ç”¨è¡¨å•æ¥ç¡®ä¿æŒ‰é’®ç‚¹å‡»å¯ä»¥æ­£ç¡®å¤„ç†
        with st.form(key="paste_content_form"):
                st.subheader("TMSLè„šæœ¬å†…å®¹ç¼–è¾‘åŒº")
                # æä¾›æ›´å¤§çš„æ–‡æœ¬åŒºåŸŸä»¥æ–¹ä¾¿ç¼–è¾‘
                pasted_content = st.text_area(
                    "è¯·ç²˜è´´TMSLè„šæœ¬å†…å®¹åˆ°æ­¤å¤„", 
                    height=500,  # å¢åŠ é«˜åº¦æä¾›æ›´å¥½çš„ç¼–è¾‘ä½“éªŒ
                    key="pasted_content_area",
                    placeholder="{\n  \"name\": \"SemanticModel\",\n  \"compatibilityLevel\": 1500,\n  ...\n}"
                )
                
                # æ·»åŠ å†…å®¹æç¤ºä¿¡æ¯
                st.info("ğŸ’¡ æç¤ºï¼šç²˜è´´å®Œæ•´çš„TMSLè„šæœ¬åï¼Œå¯ä»¥ç›´æ¥åœ¨ç¼–è¾‘åŒºè¿›è¡Œä¿®æ”¹ï¼Œç„¶åç‚¹å‡»è§£ææŒ‰é’®ã€‚")
                
                # åˆ›å»ºè¡¨å•å†…çš„æäº¤æŒ‰é’®
                parse_pasted_button = st.form_submit_button("ğŸš€ è§£æç²˜è´´å†…å®¹", use_container_width=True)
                
                # åœ¨è¡¨å•å†…ä½¿ç”¨form_submit_buttonä½œä¸ºå…³é—­æŒ‰é’®
                close_button = st.form_submit_button("âŒ å…³é—­", use_container_width=True)
                
                # å¤„ç†å…³é—­æŒ‰é’®é€»è¾‘
                if close_button:
                    st.session_state["show_paste_dialog"] = False
                    st.rerun()
                
                # å¤„ç†è§£æé€»è¾‘
                if parse_pasted_button:
                    if pasted_content.strip():
                        try:
                            # æ›´å…¨é¢çš„ç²˜è´´å†…å®¹æ¸…ç†
                            # 1. ç§»é™¤é¦–å°¾ç©ºç™½å­—ç¬¦
                            cleaned_content = pasted_content.strip()
                            
                            # 2. ç§»é™¤æ‰€æœ‰BOMæ ‡è®°
                            if cleaned_content.startswith('\ufeff'):
                                cleaned_content = cleaned_content[1:]
                            
                            # 3. ç§»é™¤å¯èƒ½å­˜åœ¨çš„å‰å¯¼/å°¾éšåƒåœ¾å­—ç¬¦
                            # æŸ¥æ‰¾ç¬¬ä¸€ä¸ª'{'å’Œæœ€åä¸€ä¸ª'}'æ¥ç¡®ä¿åªä¿ç•™JSONéƒ¨åˆ†
                            if '{' in cleaned_content and '}' in cleaned_content:
                                start_idx = cleaned_content.find('{')
                                end_idx = cleaned_content.rfind('}') + 1
                                cleaned_content = cleaned_content[start_idx:end_idx]
                            
                            # 4. å¤„ç†å¯èƒ½çš„ç©ºç™½å­—ç¬¦ç¼–ç é—®é¢˜
                            import re
                            # ç§»é™¤ä¸å¯è§çš„æ§åˆ¶å­—ç¬¦
                            cleaned_content = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', cleaned_content)
                            # æ ‡å‡†åŒ–ç©ºç™½å­—ç¬¦
                            cleaned_content = re.sub(r'\s+', ' ', cleaned_content)
                            
                            st.info(f"ğŸ“‹ å¤„ç†åçš„å†…å®¹é•¿åº¦: {len(cleaned_content)} å­—ç¬¦")
                            st.info(f"ğŸ“‹ å†…å®¹å¼€å¤´: {cleaned_content[:50]}...")
                            
                            # éªŒè¯å†…å®¹æ˜¯å¦ä¸ºæœ‰æ•ˆçš„JSONæ ¼å¼
                            try:
                                json.loads(cleaned_content)
                                st.success("âœ… JSONæ ¼å¼éªŒè¯é€šè¿‡ï¼")
                            except json.JSONDecodeError as je:
                                st.error(f"âŒ æ— æ•ˆçš„JSONæ ¼å¼: {str(je)}")
                                st.info("ğŸ’¡ æç¤ºï¼š")
                                st.info("1. è¯·ç¡®ä¿ç²˜è´´çš„æ˜¯å®Œæ•´çš„TMSLè„šæœ¬å†…å®¹")
                                st.info("2. æ£€æŸ¥æ˜¯å¦æœ‰å¤šä½™çš„å­—ç¬¦æˆ–æ ¼å¼é—®é¢˜")
                                st.info("3. å°è¯•é‡æ–°å¤åˆ¶æ–‡ä»¶å†…å®¹")
                                # æ˜¾ç¤ºæ›´å¤šè°ƒè¯•ä¿¡æ¯
                                if len(cleaned_content) < 500:
                                    st.code(cleaned_content, language="json")
                                return
                            
                            # è§£æç²˜è´´çš„å†…å®¹
                            parser = BIMParser()
                            result = parser.parse_file(cleaned_content)
                            
                            if result["success"]:
                                st.session_state['parsed_data'] = result
                                st.success("âœ… å†…å®¹è§£ææˆåŠŸï¼")
                                st.session_state["show_paste_dialog"] = False
                                # å¼ºåˆ¶åˆ·æ–°é¡µé¢ä»¥æ˜¾ç¤ºè§£æç»“æœ
                                st.rerun()
                            else:
                                st.error(f"âŒ å†…å®¹è§£æå¤±è´¥: {result['error']}")
                                st.info("ğŸ’¡ è¯·æ£€æŸ¥ç²˜è´´çš„å†…å®¹æ˜¯å¦ä¸ºæœ‰æ•ˆçš„TMSLè„šæœ¬æ ¼å¼")
                        except Exception as e:
                            st.error(f"âŒ å¤„ç†å†…å®¹æ—¶å‡ºé”™: {str(e)}")
                            st.info("ğŸ’¡ è¯·å°è¯•é‡æ–°å¤åˆ¶å®Œæ•´çš„æ¨¡å‹æ–‡ä»¶å†…å®¹")
                            import traceback
                            st.code(traceback.format_exc(), language="python")
                    else:
                        st.warning("âš ï¸ è¯·è¾“å…¥æœ‰æ•ˆçš„æ¨¡å‹å†…å®¹")
        
        st.write("---")
        st.subheader("ğŸ“‹ ä½¿ç”¨è¯´æ˜")
        st.markdown("""
        - ğŸ“ åœ¨ä¸Šæ–¹ä¸Šä¼ BIæ¨¡å‹æ–‡ä»¶ (.bim)
        - ğŸš€ ç‚¹å‡»"å¼€å§‹è§£æ"æŒ‰é’®
        - ğŸ“Š åœ¨ä¸»ç•Œé¢æŸ¥çœ‹è§£æç»“æœ
        - ğŸ” ä½¿ç”¨æœç´¢åŠŸèƒ½ç­›é€‰æ•°æ®
        - ğŸ’¾ å¯¼å‡ºéœ€è¦çš„æ ¼å¼
        """)
    
    # ä¸»ç•Œé¢
    st.markdown("## ğŸ“Š æ¬¢è¿ä½¿ç”¨BIæ¨¡å‹è§£æå·¥å…·")
    
    # å¤„ç†æ–‡ä»¶è§£æ
    if parse_button and uploaded_file is not None:
        try:
            # è¯»å–æ–‡ä»¶å†…å®¹
            file_content = uploaded_file.getvalue().decode("utf-8")
            
            # è§£ææ–‡ä»¶
            parser = BIMParser()
            result = parser.parse_file(file_content)
            
            if result["success"]:
                st.session_state['parsed_data'] = result
                st.success("âœ… æ–‡ä»¶è§£ææˆåŠŸï¼")
            else:
                st.error(f"âŒ æ–‡ä»¶è§£æå¤±è´¥: {result['error']}")
        except Exception as e:
            st.error(f"âŒ å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
    
    # æ˜¾ç¤ºè§£æç»“æœ
    if st.session_state['parsed_data'] is not None:
        data = st.session_state['parsed_data']
        
        # åˆ›å»ºæ ‡ç­¾é¡µ
        tab1, tab2, tab3, tab4 = st.tabs([
            "ğŸ“‹ è¡¨æ˜ç»†", 
            "ğŸ“ åˆ—æ˜ç»†", 
            "ğŸ“ˆ åº¦é‡å€¼", 
            "ğŸ”— è¡¨å…³ç³»"
        ])
        
        with tab1:
            overview_df = pd.DataFrame(data['overview'])
            
            if not overview_df.empty:
                # æŒ‰è¡¨ååˆ—å­—æ¯å‡åºæ’åº
                overview_df = overview_df.sort_values(by='è¡¨å', ascending=True)
                # æ·»åŠ åºå·åˆ—
                overview_df.insert(0, 'åºå·', range(1, len(overview_df) + 1))
                
                # å®æ—¶æœç´¢åŠŸèƒ½ - æ— éœ€æŒ‰å›è½¦é”®ï¼Œè¾“å…¥æ—¶è‡ªåŠ¨æœç´¢
                input_value = st.text_input(
                    "ğŸ” æœç´¢è¡¨åæˆ–è¡¨æè¿°", 
                    key="table_search_input"
                )
                
                # ç›´æ¥æ›´æ–°æœç´¢çŠ¶æ€ï¼Œæ— éœ€ç­‰å¾…å›è½¦
                update_search_timer("table_search", input_value)
                
                # è·å–æœç´¢è¯
                search_term = debounced_search("table_search")
                
                # æ ¹æ®æœç´¢è¯è¿‡æ»¤ï¼Œæ”¯æŒç©ºæœç´¢ï¼ˆæ˜¾ç¤ºæ‰€æœ‰æ•°æ®ï¼‰
                if search_term:
                    # æ„å»ºæœç´¢æ¡ä»¶ï¼Œç¡®ä¿åˆ—å­˜åœ¨æ—¶æ‰è¿›è¡Œæœç´¢
                    search_conditions = []
                    
                    # è¡¨åæœç´¢
                    if 'è¡¨å' in overview_df.columns:
                        search_conditions.append(overview_df['è¡¨å'].str.contains(search_term, case=False, na=False))
                    
                    # è¡¨æè¿°æœç´¢ - å®‰å…¨å¤„ç†å¯èƒ½ä¸å­˜åœ¨çš„åˆ—
                    if 'è¡¨æè¿°' in overview_df.columns:
                        search_conditions.append(overview_df['è¡¨æè¿°'].str.contains(search_term, case=False, na=False))
                    
                    # æºè¡¨åæœç´¢
                    if 'æºè¡¨å' in overview_df.columns:
                        search_conditions.append(overview_df['æºè¡¨å'].str.contains(search_term, case=False, na=False))
                    
                    # æ•°æ®åº“åæœç´¢
                    if 'æ•°æ®åº“å' in overview_df.columns:
                        search_conditions.append(overview_df['æ•°æ®åº“å'].str.contains(search_term, case=False, na=False))
                    
                    # åªæœ‰å½“æœ‰æœç´¢æ¡ä»¶æ—¶æ‰è¿›è¡Œè¿‡æ»¤
                    if search_conditions:
                        # ä½¿ç”¨é€»è¾‘æˆ–ç»„åˆæ‰€æœ‰æ¡ä»¶
                        combined_condition = search_conditions[0]
                        for cond in search_conditions[1:]:
                            combined_condition = combined_condition | cond
                        
                        overview_df = overview_df[combined_condition]
                
                # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
                # è¡¨æ€»æ•°ï¼šæ‰€æœ‰è¡¨åçš„é™¤é‡è®¡æ•°
                table_count = len(set(overview_df['è¡¨å']))
                
                # åˆ—æ€»æ•°ï¼šæ¯ä¸ªè¡¨çš„åˆ—åé™¤é‡è®¡æ•°åŠ æ€»
                # ä»columns_infoä¸­è·å–æ•°æ®
                columns_data = data.get('columns', [])
                column_count = len(columns_data)
                
                # åº¦é‡å€¼æ€»æ•°ï¼šåº¦é‡å€¼åç§°é™¤é‡è®¡æ•°åŠ æ€»
                measures_data = data.get('measures', [])
                measure_count = len(measures_data)
                
                # å…³ç³»æ¡æ•°ï¼šè¡¨å…³ç³»çš„æ€»æ•°
                relationships_data = data.get('relationships', [])
                relationship_count = len(relationships_data)
                
                # æ˜¾ç¤ºæ¦‚è§ˆä¿¡æ¯
                st.info(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯: è¡¨æ€»æ•° {table_count} ä¸ª, åˆ—æ€»æ•° {column_count} ä¸ª, åº¦é‡å€¼æ€»æ•° {measure_count} ä¸ª, å…³ç³»æ¡æ•° {relationship_count} ä¸ª")
                
                # é…ç½®åˆ—çš„å®½åº¦å’Œç±»å‹
                column_configs = {}
                for col in overview_df.columns:
                    if col == 'åºå·':
                        # åºå·åˆ—é…ç½®ä¸ºæ•°å­—ç±»å‹ï¼Œç¡®ä¿æ­£ç¡®æ’åº
                        column_configs[col] = st.column_config.NumberColumn(
                            col,
                            width="small"
                        )
                    elif col in ['è¡¨å', 'è¡¨æè¿°', 'å®ä¾‹åœ°å€']:
                        column_configs[col] = st.column_config.TextColumn(
                            col,
                            width="medium"
                        )
                    elif col in ['åˆ†åŒºæ•°', 'è¡Œæ•°', 'åè®®']:
                        column_configs[col] = st.column_config.TextColumn(
                            col,
                            width="small"
                        )
                    elif col in ['æ•°æ®åº“å', 'æºè¡¨å']:
                        column_configs[col] = st.column_config.TextColumn(
                            col,
                            width="medium"
                        )
                    else:
                        column_configs[col] = st.column_config.TextColumn(
                            col,
                            width="small"
                        )
                
                # è®¾ç½®è¡¨æ ¼é«˜åº¦ - è‡ªé€‚åº”è¡Œæ•°ï¼Œåªæœ‰è¶…è¿‡15è¡Œæ—¶æ‰éœ€è¦æ»šåŠ¨
                max_rows_without_scroll = 15  # ä¸æ»šåŠ¨å¯æ˜¾ç¤ºçš„æœ€å¤§è¡Œæ•°
                row_height = 35  # æ¯è¡Œé«˜åº¦
                header_height = 50  # è¡¨å¤´é«˜åº¦
                
                if len(overview_df) <= max_rows_without_scroll:
                    # å¦‚æœè¡Œæ•°è¾ƒå°‘ï¼Œå®Œå…¨è‡ªé€‚åº”æ˜¾ç¤º
                    table_height = len(overview_df) * row_height + header_height
                else:
                    # è¶…è¿‡æœ€å¤§è¡Œæ•°æ—¶ï¼Œè®¾ç½®æœ€å¤§é«˜åº¦
                    table_height = max_rows_without_scroll * row_height + header_height
                
                # æ˜¾ç¤ºè¡¨æ ¼
                st.dataframe(
                    overview_df,
                    use_container_width=True,
                    hide_index=True,
                    column_config=column_configs,
                    key="overview_table",
                    height=table_height
                )
            else:
                st.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°æ¦‚è§ˆæ•°æ®")
        
        with tab2:
            columns_df = pd.DataFrame(data['columns'])
            
            if not columns_df.empty:
                # æŒ‰è¡¨ååˆ—å­—æ¯å‡åºæ’åº
                columns_df = columns_df.sort_values(by='è¡¨å', ascending=True)
                # æ·»åŠ åºå·åˆ—
                columns_df.insert(0, 'åºå·', range(1, len(columns_df) + 1))
                
                # å®æ—¶æœç´¢åŠŸèƒ½ - ä½¿ç”¨é˜²æŠ–ä¼˜åŒ–æ€§èƒ½
                input_value = st.text_input(
                    "ğŸ” æœç´¢è¡¨åã€åˆ—åæˆ–æºåˆ—å", 
                    key="column_search_input",
                    on_change=lambda: update_search_timer("column_search", st.session_state.column_search_input)
                )
                
                # åˆå§‹åŒ–æ—¶ä¹Ÿéœ€è¦æ›´æ–°ä¸€æ¬¡å®šæ—¶å™¨
                update_search_timer("column_search", input_value)
                
                # è·å–ç»è¿‡é˜²æŠ–å¤„ç†çš„æœç´¢è¯
                debounced_term = debounced_search("column_search")
                
                # å¦‚æœæœ‰é˜²æŠ–å¤„ç†åçš„æœç´¢è¯ï¼Œåˆ™æ‰§è¡Œæœç´¢
                if debounced_term:
                    # æ„å»ºæœç´¢æ¡ä»¶ï¼Œç¡®ä¿åˆ—å­˜åœ¨æ—¶æ‰è¿›è¡Œæœç´¢
                    search_conditions = []
                    
                    # è¡¨åæœç´¢
                    if 'è¡¨å' in columns_df.columns:
                        search_conditions.append(columns_df['è¡¨å'].str.contains(debounced_term, case=False, na=False))
                    
                    # åˆ—åæœç´¢
                    if 'åˆ—å' in columns_df.columns:
                        search_conditions.append(columns_df['åˆ—å'].str.contains(debounced_term, case=False, na=False))
                    
                    # æºåˆ—åæœç´¢
                    if 'æºåˆ—å' in columns_df.columns:
                        search_conditions.append(columns_df['æºåˆ—å'].str.contains(debounced_term, case=False, na=False))
                    
                    # åªæœ‰å½“æœ‰æœç´¢æ¡ä»¶æ—¶æ‰è¿›è¡Œè¿‡æ»¤
                    if search_conditions:
                        # ä½¿ç”¨é€»è¾‘æˆ–ç»„åˆæ‰€æœ‰æ¡ä»¶
                        combined_condition = search_conditions[0]
                        for cond in search_conditions[1:]:
                            combined_condition = combined_condition | cond
                        
                        columns_df = columns_df[combined_condition]
                
                # æ˜¾ç¤ºç­›é€‰ç»“æœæ•°é‡
                st.info(f"ğŸ“ å…±æ˜¾ç¤º {len(columns_df)} æ¡åˆ—è®°å½•")
                
                # è®¾ç½®è¡¨æ ¼é«˜åº¦ - è‡ªé€‚åº”è¡Œæ•°ï¼Œåªæœ‰è¶…è¿‡15è¡Œæ—¶æ‰éœ€è¦æ»šåŠ¨
                max_rows_without_scroll = 15  # ä¸æ»šåŠ¨å¯æ˜¾ç¤ºçš„æœ€å¤§è¡Œæ•°
                row_height = 35  # æ¯è¡Œé«˜åº¦
                header_height = 50  # è¡¨å¤´é«˜åº¦
                
                if len(columns_df) <= max_rows_without_scroll:
                    # å¦‚æœè¡Œæ•°è¾ƒå°‘ï¼Œå®Œå…¨è‡ªé€‚åº”æ˜¾ç¤º
                    table_height = len(columns_df) * row_height + header_height
                else:
                    # è¶…è¿‡æœ€å¤§è¡Œæ•°æ—¶ï¼Œè®¾ç½®æœ€å¤§é«˜åº¦
                    table_height = max_rows_without_scroll * row_height + header_height
                
                # é…ç½®åˆ—çš„å®½åº¦å’Œç±»å‹
                column_configs = {}
                for col in columns_df.columns:
                    if col == 'åºå·':
                        # åºå·åˆ—é…ç½®ä¸ºæ•°å­—ç±»å‹ï¼Œç¡®ä¿æ­£ç¡®æ’åº
                        column_configs[col] = st.column_config.NumberColumn(
                            col,
                            width="small"
                        )
                    else:
                        column_configs[col] = st.column_config.TextColumn(
                            col,
                            width="medium"
                        )
                
                # æ˜¾ç¤ºè¡¨æ ¼
                st.dataframe(
                    columns_df,
                    use_container_width=True,
                    hide_index=True,
                    column_config=column_configs,
                    key="columns_table",
                    height=table_height
                )
            else:
                st.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°åˆ—æ•°æ®")
        
        with tab3:
            measures_df = pd.DataFrame(data['measures'])
            
            if not measures_df.empty:
                # æŒ‰åº¦é‡å€¼æ¶‰åŠè¡¨åˆ—å­—æ¯å‡åºæ’åº
                measures_df = measures_df.sort_values(by='åº¦é‡å€¼æ¶‰åŠè¡¨', ascending=True)
                # æ·»åŠ åºå·åˆ—
                measures_df.insert(0, 'åºå·', range(1, len(measures_df) + 1))
                
                # å®æ—¶æœç´¢åŠŸèƒ½ - æ— éœ€æŒ‰å›è½¦é”®ï¼Œè¾“å…¥æ—¶è‡ªåŠ¨æœç´¢
                input_value = st.text_input(
                    "ğŸ” æœç´¢åº¦é‡å€¼åç§°æˆ–è®¡ç®—é€»è¾‘", 
                    key="measure_search_input"
                )
                
                # ç›´æ¥æ›´æ–°æœç´¢çŠ¶æ€ï¼Œæ— éœ€ç­‰å¾…å›è½¦
                update_search_timer("measure_search", input_value)
                
                # è·å–æœç´¢è¯
                search_term = debounced_search("measure_search")
                
                # æ ¹æ®æœç´¢è¯è¿‡æ»¤ï¼Œæ”¯æŒç©ºæœç´¢ï¼ˆæ˜¾ç¤ºæ‰€æœ‰æ•°æ®ï¼‰
                if search_term:
                    # æ„å»ºæœç´¢æ¡ä»¶ï¼Œç¡®ä¿åˆ—å­˜åœ¨æ—¶æ‰è¿›è¡Œæœç´¢
                    search_conditions = []
                    
                    # åº¦é‡å€¼åç§°æœç´¢
                    if 'åº¦é‡å€¼åç§°' in measures_df.columns:
                        search_conditions.append(measures_df['åº¦é‡å€¼åç§°'].str.contains(search_term, case=False, na=False))
                    
                    # åº¦é‡å€¼è®¡ç®—é€»è¾‘æœç´¢
                    if 'åº¦é‡å€¼è®¡ç®—é€»è¾‘' in measures_df.columns:
                        search_conditions.append(measures_df['åº¦é‡å€¼è®¡ç®—é€»è¾‘'].str.contains(search_term, case=False, na=False))
                    
                    # åªæœ‰å½“æœ‰æœç´¢æ¡ä»¶æ—¶æ‰è¿›è¡Œè¿‡æ»¤
                    if search_conditions:
                        # ä½¿ç”¨é€»è¾‘æˆ–ç»„åˆæ‰€æœ‰æ¡ä»¶
                        combined_condition = search_conditions[0]
                        for cond in search_conditions[1:]:
                            combined_condition = combined_condition | cond
                        
                        measures_df = measures_df[combined_condition]
                
                # æ˜¾ç¤ºç­›é€‰ç»“æœæ•°é‡
                st.info(f"ğŸ“ˆ å…±æ˜¾ç¤º {len(measures_df)} æ¡åº¦é‡å€¼è®°å½•")
                
                # è®¾ç½®è¡¨æ ¼é«˜åº¦ - è‡ªé€‚åº”è¡Œæ•°ï¼Œåªæœ‰è¶…è¿‡15è¡Œæ—¶æ‰éœ€è¦æ»šåŠ¨
                max_rows_without_scroll = 15  # ä¸æ»šåŠ¨å¯æ˜¾ç¤ºçš„æœ€å¤§è¡Œæ•°
                row_height = 35  # æ¯è¡Œé«˜åº¦
                header_height = 50  # è¡¨å¤´é«˜åº¦
                
                if len(measures_df) <= max_rows_without_scroll:
                    # å¦‚æœè¡Œæ•°è¾ƒå°‘ï¼Œå®Œå…¨è‡ªé€‚åº”æ˜¾ç¤º
                    table_height = len(measures_df) * row_height + header_height
                else:
                    # è¶…è¿‡æœ€å¤§è¡Œæ•°æ—¶ï¼Œè®¾ç½®æœ€å¤§é«˜åº¦
                    table_height = max_rows_without_scroll * row_height + header_height
                
                # é…ç½®åˆ—çš„å®½åº¦å’Œç±»å‹
                column_configs = {}
                for col in measures_df.columns:
                    if col == 'åºå·':
                        # åºå·åˆ—é…ç½®ä¸ºæ•°å­—ç±»å‹ï¼Œç¡®ä¿æ­£ç¡®æ’åº
                        column_configs[col] = st.column_config.NumberColumn(
                            col,
                            width="small"
                        )
                    else:
                        column_configs[col] = st.column_config.TextColumn(
                            col,
                            width="medium"
                        )
                
                # æ˜¾ç¤ºè¡¨æ ¼
                st.dataframe(
                    measures_df,
                    use_container_width=True,
                    hide_index=True,
                    column_config=column_configs,
                    key="measures_table",
                    height=table_height
                )
            else:
                st.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°åº¦é‡å€¼æ•°æ®")
        
        with tab4:
            relationships_df = pd.DataFrame(data['relationships'])
            
            if not relationships_df.empty:
                # æŒ‰æºè¡¨ååˆ—å­—æ¯å‡åºæ’åº
                relationships_df = relationships_df.sort_values(by='æºè¡¨å', ascending=True)
                # æ·»åŠ åºå·åˆ—
                relationships_df.insert(0, 'åºå·', range(1, len(relationships_df) + 1))
                
                # å®æ—¶æœç´¢åŠŸèƒ½ - æ— éœ€æŒ‰å›è½¦é”®ï¼Œè¾“å…¥æ—¶è‡ªåŠ¨æœç´¢
                input_value = st.text_input(
                    "ğŸ” æœç´¢è¡¨åæˆ–å­—æ®µå", 
                    key="relationship_search_input"
                )
                
                # ç›´æ¥æ›´æ–°æœç´¢çŠ¶æ€ï¼Œæ— éœ€ç­‰å¾…å›è½¦
                update_search_timer("relationship_search", input_value)
                
                # è·å–æœç´¢è¯
                search_term = debounced_search("relationship_search")
                
                # æ ¹æ®æœç´¢è¯è¿‡æ»¤ï¼Œæ”¯æŒç©ºæœç´¢ï¼ˆæ˜¾ç¤ºæ‰€æœ‰æ•°æ®ï¼‰
                if search_term:
                    # æ„å»ºæœç´¢æ¡ä»¶ï¼Œç¡®ä¿åˆ—å­˜åœ¨æ—¶æ‰è¿›è¡Œæœç´¢
                    search_conditions = []
                    
                    # æºè¡¨åæœç´¢
                    if 'æºè¡¨å' in relationships_df.columns:
                        search_conditions.append(relationships_df['æºè¡¨å'].str.contains(search_term, case=False, na=False))
                    
                    # ç›®æ ‡è¡¨åæœç´¢
                    if 'ç›®æ ‡è¡¨å' in relationships_df.columns:
                        search_conditions.append(relationships_df['ç›®æ ‡è¡¨å'].str.contains(search_term, case=False, na=False))
                    
                    # æºè¡¨å­—æ®µæœç´¢
                    if 'æºè¡¨å­—æ®µ' in relationships_df.columns:
                        search_conditions.append(relationships_df['æºè¡¨å­—æ®µ'].str.contains(search_term, case=False, na=False))
                    
                    # ç›®æ ‡è¡¨å­—æ®µæœç´¢
                    if 'ç›®æ ‡è¡¨å­—æ®µ' in relationships_df.columns:
                        search_conditions.append(relationships_df['ç›®æ ‡è¡¨å­—æ®µ'].str.contains(search_term, case=False, na=False))
                    
                    # åªæœ‰å½“æœ‰æœç´¢æ¡ä»¶æ—¶æ‰è¿›è¡Œè¿‡æ»¤
                    if search_conditions:
                        # ä½¿ç”¨é€»è¾‘æˆ–ç»„åˆæ‰€æœ‰æ¡ä»¶
                        combined_condition = search_conditions[0]
                        for cond in search_conditions[1:]:
                            combined_condition = combined_condition | cond
                        
                        relationships_df = relationships_df[combined_condition]
                
                # æ˜¾ç¤ºç­›é€‰ç»“æœæ•°é‡
                st.info(f"ğŸ”— å…±æ˜¾ç¤º {len(relationships_df)} æ¡å…³ç³»è®°å½•")
                
                # è®¾ç½®è¡¨æ ¼é«˜åº¦ - è‡ªé€‚åº”è¡Œæ•°ï¼Œåªæœ‰è¶…è¿‡15è¡Œæ—¶æ‰éœ€è¦æ»šåŠ¨
                max_rows_without_scroll = 15  # ä¸æ»šåŠ¨å¯æ˜¾ç¤ºçš„æœ€å¤§è¡Œæ•°
                row_height = 35  # æ¯è¡Œé«˜åº¦
                header_height = 50  # è¡¨å¤´é«˜åº¦
                
                if len(relationships_df) <= max_rows_without_scroll:
                    # å¦‚æœè¡Œæ•°è¾ƒå°‘ï¼Œå®Œå…¨è‡ªé€‚åº”æ˜¾ç¤º
                    table_height = len(relationships_df) * row_height + header_height
                else:
                    # è¶…è¿‡æœ€å¤§è¡Œæ•°æ—¶ï¼Œè®¾ç½®æœ€å¤§é«˜åº¦
                    table_height = max_rows_without_scroll * row_height + header_height
                
                # é…ç½®åˆ—çš„å®½åº¦å’Œç±»å‹
                column_configs = {}
                for col in relationships_df.columns:
                    if col == 'åºå·':
                        # åºå·åˆ—é…ç½®ä¸ºæ•°å­—ç±»å‹ï¼Œç¡®ä¿æ­£ç¡®æ’åº
                        column_configs[col] = st.column_config.NumberColumn(
                            col,
                            width="small"
                        )
                    else:
                        column_configs[col] = st.column_config.TextColumn(
                            col,
                            width="medium"
                        )
                
                # æ˜¾ç¤ºè¡¨æ ¼
                st.dataframe(
                    relationships_df,
                    use_container_width=True,
                    hide_index=True,
                    column_config=column_configs,
                    key="relationships_table",
                    height=table_height
                )
            else:
                st.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°å…³ç³»æ•°æ®")
            
            # æ¢å¤å¯¼å‡ºåŠŸèƒ½ - æ·»åŠ åˆ°ä¾§è¾¹æ ï¼Œå¹¶ä¼˜åŒ–æ ·å¼
            with st.sidebar.expander("ğŸ“¤ æ•°æ®å¯¼å‡º", expanded=False):
                # æ·»åŠ CSSæ ·å¼ä¼˜åŒ–å¸ƒå±€å’Œå­—ä½“å¤§å°
                st.markdown(
                    """
                    <style>
                        .export-sidebar * {
                            font-size: 0.75rem !important;
                            margin-bottom: 0 !important;
                            margin-top: 0 !important;
                            line-height: 1.1;
                        }
                        .export-sidebar .stVerticalBlock {
                            gap: 0 !important;
                        }
                        .export-sidebar .stButton button {
                            height: 28px !important;
                            padding: 0.1rem 0.3rem !important;
                            margin-top: 0 !important;
                            margin-bottom: 0 !important;
                        }
                        .export-sidebar .stAlert {
                            margin-top: 0 !important;
                            margin-bottom: 0 !important;
                            padding: 0.2rem !important;
                            font-size: 0.7rem !important;
                        }
                        .export-sidebar .stSelectbox {
                            margin-bottom: 0 !important;
                            margin-top: 0 !important;
                            padding: 0 !important;
                        }
                        .export-sidebar h3 {
                            font-size: 0.7rem !important;
                            margin-bottom: 0 !important;
                        }
                        .export-sidebar {
                            font-size: 0.75rem !important;
                            margin-top: -15px !important;
                            padding: 0 !important;
                            line-height: 1.0 !important;
                        }
                        .export-sidebar > *:first-child {
                            margin-top: 0 !important;
                        }
                        .export-sidebar .stLabel {
                            margin-bottom: 0 !important;
                            margin-top: 0 !important;
                        }
                        .export-sidebar .stMarkdown {
                            margin-bottom: 0 !important;
                            margin-top: 0 !important;
                        }
                        .export-sidebar .stSelectbox div[data-baseweb="select"] {
                            margin-top: 0 !important;
                            margin-bottom: 0 !important;
                        }
                        .export-sidebar .stButton {
                            margin-top: 0 !important;
                            margin-bottom: 0 !important;
                        }
                    </style>
                    """,
                    unsafe_allow_html=True
                )
                
                st.markdown('<div class="export-sidebar">', unsafe_allow_html=True)
                # é€‰æ‹©è¦å¯¼å‡ºçš„æ•°æ®ç±»å‹ - ä¸é¡µé¢æ˜¾ç¤ºä¿æŒä¸€è‡´
                export_type = st.selectbox(
                    "é€‰æ‹©æ•°æ®ç±»å‹",
                    ["è¡¨æ˜ç»†", "åˆ—æ˜ç»†", "åº¦é‡å€¼", "è¡¨å…³ç³»", "å…¨éƒ¨å¯¼å‡º"],
                    index=4  # é»˜è®¤é€‰æ‹©"å…¨éƒ¨å¯¼å‡º"
                )
                # é€‰æ‹©å¯¼å‡ºæ ¼å¼
                export_format = st.selectbox(
                    "é€‰æ‹©å¯¼å‡ºæ ¼å¼",
                    ["CSV", "Excel"],
                    index=1  # é»˜è®¤é€‰æ‹©"Excel"
                )
                
                # æ·»åŠ éšè—çš„ä¼šè¯çŠ¶æ€å˜é‡ç”¨äºè·Ÿè¸ªä¸‹è½½çŠ¶æ€
                if "export_data" not in st.session_state:
                    st.session_state.export_data = None
                if "export_filename" not in st.session_state:
                    st.session_state.export_filename = None
                if "export_mime" not in st.session_state:
                    st.session_state.export_mime = None
                if "export_ready" not in st.session_state:
                    st.session_state.export_ready = False
                
                # å¯¼å‡ºæŒ‰é’®ï¼šè¾ƒä¸ºç¨³å¥çš„å®ç°ï¼ŒExcel å°½é‡å»¶è¿Ÿä½¿ç”¨ openpyxlï¼Œå¦åˆ™å›é€€ä¸º CSV ZIP
                if st.button("å¼€å§‹å¯¼å‡º", use_container_width=True):
                    try:
                        if export_type == "å…¨éƒ¨å¯¼å‡º":
                            sheet_data = [
                                ('è¡¨æ˜ç»†', data['overview']),
                                ('åˆ—æ˜ç»†', data['columns']),
                                ('åº¦é‡å€¼', data['measures']),
                                ('è¡¨å…³ç³»', data['relationships'])
                            ]

                            # å¦‚æœç”¨æˆ·é€‰æ‹© Excelï¼Œä½† openpyxl ä¸å¯ç”¨ -> å›é€€ä¸º CSV ZIP
                            if export_format == 'Excel' and not _OPENPYXL_AVAILABLE:
                                st.warning("å½“å‰ç¯å¢ƒæœªå®‰è£… openpyxlï¼Œå·²é€€å›ä¸º CSV å‹ç¼©åŒ…å¯¼å‡ºã€‚è‹¥éœ€ Excel è¾“å‡ºï¼Œè¯·å®‰è£… openpyxl å¹¶é‡è¯•ã€‚")
                                export_format = 'CSV'

                            if export_format == 'CSV':
                                zip_buffer = io.BytesIO()
                                with zipfile.ZipFile(zip_buffer, mode='w', compression=zipfile.ZIP_DEFLATED) as zf:
                                    for sheet_name, sheet_rows in sheet_data:
                                        df_sheet = pd.DataFrame(sheet_rows)
                                        csv_bytes = df_sheet.to_csv(index=False).encode('utf-8')
                                        zf.writestr(f"{sheet_name}.csv", csv_bytes)

                                zip_buffer.seek(0)
                                filename = f"bi_model_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip"
                                st.success("âœ… æ•°æ®å‡†å¤‡å®Œæˆï¼Œç‚¹å‡»ä¸‹æ–¹æŒ‰é’®ä¸‹è½½")
                                st.download_button("â¬‡ï¸ ä¸‹è½½ ZIP (CSV)", data=zip_buffer.getvalue(), file_name=filename, mime='application/zip')
                            else:
                                output = io.BytesIO()
                                with pd.ExcelWriter(output, engine='openpyxl') as writer:
                                    for sheet_name, sheet_rows in sheet_data:
                                        df_sheet = pd.DataFrame(sheet_rows)
                                        df_sheet.to_excel(writer, sheet_name=sheet_name[:31], index=False)

                                output.seek(0)
                                filename = f"bi_model_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
                                st.success("âœ… æ•°æ®å‡†å¤‡å®Œæˆï¼Œç‚¹å‡»ä¸‹æ–¹æŒ‰é’®ä¸‹è½½")
                                st.download_button("â¬‡ï¸ ä¸‹è½½ Excel", data=output.getvalue(), file_name=filename, mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')
                                st.markdown("<style>.stSidebar [data-testid='stVerticalBlock'] {gap: 0.2rem;}</style>", unsafe_allow_html=True)
                        else:
                            # å¯¼å‡ºç‰¹å®šç±»å‹ï¼ˆè¡¨æ˜ç»†/åˆ—æ˜ç»†/åº¦é‡å€¼/è¡¨å…³ç³»ï¼‰
                            if export_type == "è¡¨æ˜ç»†":
                                export_df = pd.DataFrame(data['overview'])
                                export_df.insert(0, 'åºå·', range(1, len(export_df) + 1))
                                file_name = f"è¡¨æ˜ç»†_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                            elif export_type == "åˆ—æ˜ç»†":
                                export_df = pd.DataFrame(data['columns'])
                                export_df.insert(0, 'åºå·', range(1, len(export_df) + 1))
                                if 'column_search' in st.session_state and st.session_state['column_search']:
                                    search_term = st.session_state['column_search']
                                    export_df = export_df[
                                        export_df['è¡¨å'].str.contains(search_term, case=False, na=False) |
                                        export_df['åˆ—å'].str.contains(search_term, case=False, na=False) |
                                        export_df['æºåˆ—å'].str.contains(search_term, case=False, na=False) |
                                        export_df.get('åˆ—æè¿°', '').str.contains(search_term, case=False, na=False)
                                    ]
                                file_name = f"åˆ—æ˜ç»†_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                            elif export_type == "åº¦é‡å€¼":
                                export_df = pd.DataFrame(data['measures'])
                                export_df.insert(0, 'åºå·', range(1, len(export_df) + 1))
                                if 'measure_search' in st.session_state and st.session_state['measure_search']:
                                    search_term = st.session_state['measure_search']
                                    export_df = export_df[
                                        export_df['åº¦é‡å€¼åç§°'].str.contains(search_term, case=False, na=False) |
                                        export_df['åº¦é‡å€¼è®¡ç®—é€»è¾‘'].str.contains(search_term, case=False, na=False) |
                                        export_df['åº¦é‡å€¼æ¶‰åŠè¡¨'].str.contains(search_term, case=False, na=False)
                                    ]
                                file_name = f"åº¦é‡å€¼_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                            elif export_type == "è¡¨å…³ç³»":
                                export_df = pd.DataFrame(data['relationships'])
                                export_df.insert(0, 'åºå·', range(1, len(export_df) + 1))
                                if 'relationship_search' in st.session_state and st.session_state['relationship_search']:
                                    search_term = st.session_state['relationship_search']
                                    export_df = export_df[
                                        export_df['æºè¡¨å'].str.contains(search_term, case=False, na=False) |
                                        export_df['ç›®æ ‡è¡¨å'].str.contains(search_term, case=False, na=False) |
                                        export_df['æºè¡¨å­—æ®µ'].str.contains(search_term, case=False, na=False) |
                                        export_df['ç›®æ ‡è¡¨å­—æ®µ'].str.contains(search_term, case=False, na=False)
                                    ]
                                file_name = f"è¡¨å…³ç³»_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

                            # è¾“å‡ºä¸º CSV æˆ– Excel
                            if export_format == "CSV":
                                csv_data = export_df.to_csv(index=False, encoding='utf-8-sig')
                                st.session_state.export_data = csv_data
                                st.session_state.export_filename = f"{file_name}.csv"
                                st.session_state.export_mime = "text/csv"
                                st.session_state.export_ready = True
                            else:
                                if not _OPENPYXL_AVAILABLE:
                                    st.error("å¯¼å‡º Excel éœ€è¦å®‰è£… openpyxlã€‚è¯·åœ¨è¿è¡Œç¯å¢ƒä¸­å®‰è£…åé‡è¯•ã€‚")
                                    raise RuntimeError("openpyxl ä¸å¯ç”¨")

                                output = io.BytesIO()
                                with pd.ExcelWriter(output, engine='openpyxl') as writer:
                                    export_df.to_excel(writer, index=False)

                                output.seek(0)
                                st.session_state.export_data = output.getvalue()
                                st.session_state.export_filename = f"{file_name}.xlsx"
                                st.session_state.export_mime = "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                                st.session_state.export_ready = True

                            # æ˜¾ç¤ºä¸‹è½½æŒ‰é’®
                            st.success("âœ… æ•°æ®å‡†å¤‡å®Œæˆï¼Œç‚¹å‡»ä¸‹æ–¹æŒ‰é’®ä¸‹è½½")
                            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                            if export_format == "CSV":
                                st.download_button(
                                    label=f"ä¸‹è½½ {export_type}.csv",
                                    data=st.session_state.export_data,
                                    file_name=f"BIæ¨¡å‹è§£ææ•°æ®_{export_type}_{timestamp}.csv",
                                    mime="text/csv",
                                    use_container_width=True,
                                    key=f"download_csv_{datetime.now().timestamp()}"
                                )
                            else:
                                st.download_button(
                                    label=f"ä¸‹è½½ {export_type}.xlsx",
                                    data=st.session_state.export_data,
                                    file_name=f"BIæ¨¡å‹è§£ææ•°æ®_{export_type}_{timestamp}.xlsx",
                                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                    use_container_width=True,
                                    key=f"download_excel_{datetime.now().timestamp()}"
                                )
                                st.markdown("<style>.stSidebar [data-testid='stVerticalBlock'] {gap: 0.2rem;}</style>", unsafe_allow_html=True)
                    except Exception as e:
                        st.error(f"âŒ å¯¼å‡ºå¤±è´¥: {str(e)}")

                # ç®€åŒ–çš„å¯¼å‡ºæµç¨‹ - ä½¿ç”¨StreamlitåŸç”Ÿä¸‹è½½æŒ‰é’®
                st.markdown('</div>', unsafe_allow_html=True)  # å…³é—­æ ·å¼å®¹å™¨
    else:
        # æ¬¢è¿ç•Œé¢ - ä½¿ç”¨StreamlitåŸç”Ÿç»„ä»¶æ›¿ä»£HTML
        st.container()
        col1, col2, col3 = st.columns([1, 3, 1])
        with col2:
            st.subheader("âœ¨ ä¸»è¦åŠŸèƒ½")
            st.markdown("""
            - âœ… è§£æBIæ¨¡å‹ç»“æ„ä¿¡æ¯
            - âœ… æ™ºèƒ½æœç´¢å’Œç­›é€‰
            - âœ… æ•°æ®å¯¼å‡º
            """)
            
            st.subheader("ğŸ“š ä½¿ç”¨æ•™ç¨‹")
            st.markdown("""
            - ğŸ“ åœ¨å·¦ä¾§ä¸Šä¼ BIæ¨¡å‹.BIMæ–‡ä»¶æˆ–ç²˜è´´TMSLè„šæœ¬
            - ğŸš€ ç‚¹å‡»"å¼€å§‹è§£æ"æŒ‰é’®
            - ğŸ“Š åœ¨å„ä¸ªæ ‡ç­¾é¡µæŸ¥çœ‹è§£æç»“æœ
            - ğŸ” ä½¿ç”¨æœç´¢åŠŸèƒ½å¿«é€Ÿå®šä½
            - ğŸ’¾ å¯¼å‡ºéœ€è¦çš„æ ¼å¼
            """)
            
            st.error("ğŸ“¢ è¯·åœ¨å·¦ä¾§ä¸Šä¼ æ‚¨çš„BIæ¨¡å‹æ–‡ä»¶ï¼")

if __name__ == "__main__":
    create_streamlit_app()